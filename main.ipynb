{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/dani/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/dani/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/dani/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/dani/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/dani/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/dani/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/dani/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: filelock in /home/dani/.local/lib/python3.10/site-packages (from torch) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in /home/dani/.local/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/dani/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/dani/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/dani/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/dani/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/dani/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/dani/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: fsspec in /home/dani/.local/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/dani/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/dani/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/dani/.local/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/dani/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dani/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/dani/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_FOLDER = \"release\"\n",
    "DATASET1_TRAIN = \"pan23-multi-author-analysis-dataset1/pan23-multi-author-analysis-dataset1-train\"\n",
    "FILES_PATH = f'{PARENT_FOLDER}/{DATASET1_TRAIN}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recollect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_files(parent_folder: str, dataset_folder: str, ini_range: int = 1, last_range: int = 200) -> pd.DataFrame:\n",
    "    data = []\n",
    "\n",
    "    for i in range(1, 4200):\n",
    "        problem_file = os.path.join(parent_folder, dataset_folder, f\"problem-{i}.txt\")\n",
    "        truth_file = os.path.join(parent_folder, dataset_folder, f\"truth-problem-{i}.json\")\n",
    "\n",
    "        if os.path.exists(problem_file) and os.path.exists(truth_file):\n",
    "            with open(problem_file, 'r') as problem_f, open(truth_file, 'r') as truth_f:\n",
    "                x_value = problem_f.read().strip()\n",
    "                y_value = json.load(truth_f)\n",
    "            data.append({'X': x_value, 'authors': y_value['authors'], 'y': y_value['changes']})\n",
    "\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data found in the specified files.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4199"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = create_dataframe_from_files(PARENT_FOLDER, DATASET1_TRAIN)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, authors, y):\n",
    "        self.X = X\n",
    "        self.authors = authors\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.authors[index], self.y[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, n_heads, n_layers, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = nn.Transformer(d_model=input_dim, nhead=n_heads, num_encoder_layers=n_layers, dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src)\n",
    "        output = self.fc(src)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 512\n",
    "HIDDEN_DIM = 256\n",
    "N_HEADS = 8\n",
    "N_LAYERS = 6\n",
    "DROPOUT = 0.2\n",
    "OUTPUT_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(INPUT_DIM, OUTPUT_DIM, HIDDEN_DIM, N_HEADS, N_LAYERS, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "dataset_train = CustomDataset(train_data['X'].values, train_data['authors'].values, train_data['y'].values)\n",
    "dataset_val = CustomDataset(val_data['X'].values, val_data['authors'].values, val_data['y'].values)\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "val_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I just don\\'t want the OP to walk away from this thread thinking that if she tries to move and her husband files for the \"emergency hearing\" that it would make her a criminal or cause her to lose custody, when all it would actually mean is that she would need to bring the kids back.\\nWould OP be worse off, legally, if she took the kids and the husband filed the emergency hearing and she brought the kids back, versus OP not leaving at all? (Ignoring any logistical issues that may or may not exist with OP leaving and then returning.) It seems to me that if she leaves, there\\'s a possibility she would be able to stay in the new location, whereas if she sticks around she simply makes it much easier for her husband to keep her there in the future.\\nI don\\'t know. I don\\'t the particulars of OP\\'s life. There may be a secondary option that she move out, but stay in the state, file for custody and have it transferred to the state she has more ties to. It sounds like neither parent has any real connection to georgia.'\n",
      " 'Yes i am aware but i already had been penalized for that back in march and since it was my first offense, they told me i had to pay a reinstatement fee and carry sr22 for 4 years, which I did and am doing both, they said open and shut case. I am confused how they are trying me for this again months later after i already did everything i was supposed to do. Does that make sense?\\nIf the other driver\\'s insurer said that all you had to do is pay the deductible and you can prove that through written communications or because the call was recorded (insurers regularly record calls), you may have a good defense to any debt collection action on the basis that you settled or came to what is termed an \"accord and satisfaction.\" If that was simply your understanding, however, or it was not clear in the communications, you are probably liable for the full amount of damages. Given what you said about the amount and your age and income, I\\'d ask any attorney you consult about whether you should consider filing for bankruptcy to clear this debt quickly so it isn\\'t hanging over your head for the next 7 or 8 years.'\n",
      " 'In general, be courteous to others. Debate/discuss/argue the merits of ideas, don\\'t attack people. Personal insults, shill or troll accusations, hate speech, any suggestion or support of harm, violence, or death, and other rule violations can result in a permanent ban.\\nYes. He replaced key people to make sure his coup would be successful. Thank God it didn’t succeed or we’d now be a dictatorship with Trump and family acting like royalty.\\nExactly. Congress don\\'t give a shit what race you are when their own life is in danger. Only reason nat guard wasn\\'t there is because trump deliberately prevented them from being there.\\nr/politics is currently accepting new moderator applications. If you want to help make this community a better place, consider !\\nThe Republican/conservative response would be fucking sensational. They wouldn\\'t be demanding that you \"get over it\", they wouldn\\'t whitewash and downplay what happened, they wouldn\\'t make excuses, they wouldn\\'t search endlessly for a way to rationalize or justify it, they wouldn\\'t call it a \"false flag\", they wouldn\\'t dismiss the gravity of what happened, they wouldn\\'t have voted against an investigation.'\n",
      " ...\n",
      " 'Thank you very much. So while the Soviet Union did undeniably bad things (war crimes, forced emigration, gulags) they never practiced genocide in the same manner as the German Nazis? Is that a correct conclusion?\\nDuring the deportation and arrival in their new homeland these people had to face immense hardships, often many perished during the journey or the early years of settlement, as the new lands were generally underdeveloped. But the express function of the deportation was not to commit complete genocide but rather to get these people somewhere else where they could do no harm and still be somewhat useful in the Soviet system and serve as an example to those who remained behind.\\nWhile the Soviet-Union practised deportation and punishment along ethnic lines, they did not set up true death camps with the purpose of just killing people. Under the rule of Stalin especially deportation of native peoples to Siberia and Central Asia took place on a massive scale.\\nNow while the Soviets did have forced labour camps, gulags, they were once again not purposefully made to kill entire groups of people. Conditions could be extreme as prisoners held there faced famine and repression and many people did not make it out. Inmates send there served as an example to society, what would happen to criminals, collaborators and those trying to undermine the state and were made to do forced labour such as mining, building railroads or other work.'\n",
      " '\"The heavy infantrymen must be deployed two deep in a double faced formation, and keep two infantrymen in front and two in the back. Between them are three light archers, so that the depth of the formation is seven men. We do find the ancient Macedonians making their phalanx sixteen men deep, occasionally twelve or ten. But because their adversaries were borne by elephants with wild beasts set loose among their formations, as we find the Ethiopians did against Alexander the Great, they also employed other methods in their wars in addition to these and for these reasons made use of such formations.\\nBut the broad strokes of it are pretty straightforward. At the beginning of Alexei Komnenos\\' reign, the Byzantine Empire came very, very close to not existing at all. It lost almost all of its land and almost all of its money. A series of disastrous military campaigns, one after another, led to army after army being decimated without the resources to rebuild. This was not a sudden, sharp event, it was a gradual process of erosion culminating in a few very nasty battles. For a long time, the Byzantines had been having an increasingly difficult time recruiting native Byzantines into the armies at all, for a whole slew of reasons from currency devaluation to the changing role of the military within the political culture.\\nI see How interesting Thank you! Terrific write up. As a lover of history, it was just an absolute pleasure to read. Fascinating.\\nBy 1263 it becomes difficult to even speak of a \"Byzantine Army\" at all. The sack of Constantinople in 1204 effectively destroyed the political entity that had existed since the classical period, leaving behind small feuding rump states led by Byzantine nobles, and the armed forces were mostly just the hired bodyguard and personal household regiments of those leaders rather than an arm of the state, plus whatever mercenaries could be recruited on an ad hoc basis.\\nWhat is this quote referring to? AFAIK, Alexander never went further into Africa than Egypt. Where would he have fought Ethiopians aided by presumably African elephants? (I know \"Ethiopian\" was historically used much more broadly than today.).\\nThe still-classical military of Justinian, the fragmented and disorganized military Heraclius barely managed to whip into coherent order against the Persians and then Arabs, the diffused and defensive asymmetrical warfare Theme system deployed against centuries of constant and overwhelmingly powerful Arab raids, the ascendant and astonishingly well oiled machine of conquest in the 10th and 11th centuries, the highly centralized but largely non-Byzantine mercenary armies of the Komnenian era, and the disparate melting pot of all sorts of different raag military forces that fought in the endless civil wars of the late Byzantine period were all quite different from one another in terms of tactics, organization, makeup, and basic purpose.\\nTake that with a grain of salt, though, because I\\'m currently trying to become a public librarian. Which despite what many think, has very little reading involved.\\nA professional military is an institution. You can\\'t just hire men, hand them weapons, and put them in the field and expect them to function. The traditions, training, hierarchies, accumulated expertise, and general institutional fabric are necessary.\\nThanks! I wouldn\\'t necessarily advise switching too far from your viewpoint, certainly for the 9th century thematic system, which had very limited successes in offensive campaigns. In the 10th century, the thematic infantry were kept in a square formation for pretty much the reasons you mentioned with the caveat that there are long discussions in the Praecepta about the extensive number of officers and where they were stationed in the square formation.\\nIt was a question of access. In the ancient world, there were breeding populations of elephants in North Africa and parts of the Middle East. By the medieval period, there were not.\\nIt\\'s difficult to highlight an absence of evidence, however, another manual published under (or soon after the death of) Nikephoros II Phokas, called On Skirmishing, makes no reference to earlier tactics and strategies, instead keeping to very contemporary approaches of tracking the enemy, working out their size and force composition, shadowing them, and either attacking smaller raiding parties or forcing the invading force to not send out raiding parties at all. \\\\[Three Byzantine Treaties, George T. Dennis\\\\].'\n",
      " \"In general, be courteous to others. Debate/discuss/argue the merits of ideas, don't attack people. Personal insults, shill or troll accusations, hate speech, any suggestion or support of harm, violence, or death, and other rule violations can result in a permanent ban.\\nSorry. Fifty years of voting has brought nothing to people like me. Oh, I’m still gonna vote D — and that makes me even more furious. I saw Dick Nixon resign August 1974 In the 50 intervening years, the Democrats have fumbled every play. WE DO NOT HAVE UNIVERSAL HEALTH CARE Billionaires do not pay their fair share of taxes The War on Drugs The constant wars of imperialism all over the globe AT THE EXPENSE OF THE HEALTH, EDUCATION, AND WELFARE of every American The Supreme Court! It’s difficult for me to breathe sometimes when I think about how weak and defenseless the Democrats are, how feckless they have always been, and how they do nothing for people who work for a living. Save your innocuous platitudes for someone with hope. I ain’t got none. Democrats suck and Republicans are theocratic fascists. Goody.\\nWhich should come as no surprise to anyone who’s bothered to notice the Republican Party’s structural weaknesses and inability to form a coherent coalition.\\nOh. Republicans are totally coherent to themselves — you don’t resonate with what they want, and you’re hoping Republicans don’t matter, but they do. Republicans have gotten everything: the Supreme Court is now a religious body; we are failing to confront Russia because the Rs want us to BECOME Russia; our global climate is destroyed. You may think it’s not too late, but it is. The Rs have totally destroyed the wall between church and state. It’s just worse and worse after this. Sorry! I have voted against them since 1972, but they have won.\\nr/politics is currently accepting new moderator applications. If you want to help make this community a better place, consider !\"]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3359\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_data)\n",
    "        loss = criterion(output, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in val_loader:\n",
    "            output = model(batch_data)\n",
    "            loss = criterion(output, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += predicted.eq(batch_labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X          Fighting between Israel and Arab states, namel...\n",
       "authors                                                    2\n",
       "y                                                        [1]\n",
       "Name: 2767, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[2767]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14035/1525647889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (batch_data, batch_labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_data)\n",
    "        loss = criterion(output, batch_labels)\n",
    "\n",
    "        # Debugging: Print the shapes of batch_data and batch_labels\n",
    "        print(f\"Batch {batch_idx}: Data shape - {batch_data.shape}, Labels shape - {batch_labels.shape}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] Train Loss: {loss.item():.4f}')\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    val_loss, val_accuracy = evaluate(model, val_loader, criterion)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
